from LLMmodel import LLM_model
from LLMmodel import LLM_psychology
from LLMmodel import LLM_fitness
from LLMmodel import LLM_compus
from LLMmodel import LLM_paper
from faiss_store_y import FAISSVectorStore  # å¼•å…¥FAISSå‘é‡å­˜å‚¨
from retrieve_model import retrieve_relevant_chunks
from sentence_transformers import SentenceTransformer
from sentence_transformers import CrossEncoder
import torch
import os

#ä»Pathæ–‡ä»¶é‡Œé¢å¼•å…¥çŸ¥è¯†åº“æ–‡ä»¶åœ°å€,ç´¢å¼•æ–‡ä»¶çš„åœ°å€
from Utils.Path import (
    PAPER_DOCS_DIR, CAMPUS_DOCS_DIR, FITNESS_DOCS_DIR, PSYCHOLOGY_DOCS_DIR,
    PAPER_INDEX_DIR, CAMPUS_INDEX_DIR, FITNESS_INDEX_DIR, PSYCHOLOGY_INDEX_DIR,
    ALL_PROCESSED_IMAGES_DIR,CAMPUS_IMAGES_DIR,PAPER_IMAGES_DIR,FITNESS_IMAGES_DIR,  PSYCHOLOGY_IMAGES_DIR,
    CAMPUS_PROCESSED_EXTRACTED_IMAGES,
    CAMPUS_EXTRACTED_IMAGES_JSON,
    CAMPUS_IMAGES_PATH
)

collection_name = "document_embeddings"
local_model_path = "./cross-encoder-model"


class RAG():
    def __init__(self):
        self.tim = 0
        # å­ç±»å¯ä»¥é‡å†™è¿™äº›å±æ€§ï¼ˆåœ¨è°ƒç”¨super()._init_()ä¹‹å‰è®¾ç½®ï¼‰
        if not hasattr(self, 'index_path'):
            self.index_path = "./faiss_index"
        if not hasattr(self, 'collection'):
            self.collection = "document_embeddings"

        # âœ… ä¿®å¤ï¼šä½¿ç”¨å®é™…çš„ self.index_path å’Œ self.collection
        print(f"ğŸ”§ åˆå§‹åŒ–å‘é‡å­˜å‚¨: index_path={self.index_path}, collection={self.collection}")
        self.vector_store = FAISSVectorStore(
            index_path=self.index_path,  # âœ… ä½¿ç”¨å­ç±»è®¾ç½®çš„è·¯å¾„
            collection_name=self.collection  # âœ… ä½¿ç”¨å­ç±»è®¾ç½®çš„é›†åˆå
        )

        # å­ç±»å¯ä»¥é‡å†™LLMå±æ€§
        if not hasattr(self, 'llm'):
            self.llm = LLM_model()
        self.llm.start_LLM()

        # ä¼˜åŒ–ï¼šæ£€æŸ¥CUDAå¯ç”¨æ€§
        self.device = "cuda" if torch.cuda.is_available() else "cpu"

        # ä¼˜åŒ–ï¼šå»¶è¿ŸåŠ è½½æ¨¡å‹ä»¥å‡å°‘åˆå§‹åŒ–æ—¶é—´
        self._cross_encoder = None
        self._embedding_model = None
    
    @property
    def cross_encoder(self):
        """å»¶è¿ŸåŠ è½½äº¤å‰ç¼–ç å™¨"""
        if self._cross_encoder is None:
            self._cross_encoder = CrossEncoder(local_model_path)
        return self._cross_encoder
    
    @property
    def model(self):
        """å»¶è¿ŸåŠ è½½åµŒå…¥æ¨¡å‹"""
        if self._embedding_model is None:
            self._embedding_model = SentenceTransformer(
                "./Qwen3-Embedding-0.6B",
                tokenizer_kwargs={"padding_side": "left"},
                trust_remote_code=True,
                device=self.device
            )
        return self._embedding_model
    


    def call_RAG_stream(self, query):
        """æµå¼RAGè°ƒç”¨
        
        Args:
            query: ç”¨æˆ·æŸ¥è¯¢
        """
        chunks = retrieve_relevant_chunks(
            user_query=query,
            vector_store=self.vector_store,
            embedding_model=self.model,
            cross_encoder1=self.cross_encoder
        )
        # å°†æ£€ç´¢åˆ°çš„å­—å…¸ç‰‡æ®µå®‰å…¨æ ¼å¼åŒ–ä¸ºå­—ç¬¦ä¸²ï¼Œé¿å…åç»­ join å¤±è´¥
        formatted_chunks = self._format_chunks_for_prompt(chunks)

        for delta in self.llm.call_llm_stream(query, formatted_chunks):
            yield delta

    def call_RAG(self, query):
        """æ ‡å‡†RAGè°ƒç”¨
        
        Args:
            query: ç”¨æˆ·æŸ¥è¯¢
        """
        chunks = retrieve_relevant_chunks(
            user_query=query,
            vector_store=self.vector_store,
            embedding_model=self.model,
            cross_encoder1=self.cross_encoder
        )
        # å°†æ£€ç´¢åˆ°çš„å­—å…¸ç‰‡æ®µå®‰å…¨æ ¼å¼åŒ–ä¸ºå­—ç¬¦ä¸²ï¼Œé¿å…åç»­ join å¤±è´¥
        formatted_chunks = self._format_chunks_for_prompt(chunks)

        return self.llm.call_llm(query, formatted_chunks)

    def _format_chunks_for_prompt(self, chunks):
        """å°†æ£€ç´¢åˆ°çš„ç‰‡æ®µï¼ˆå¯èƒ½åŒ…å«å­—å…¸ï¼‰ç»Ÿä¸€æ ¼å¼åŒ–ä¸ºå­—ç¬¦ä¸²åˆ—è¡¨ã€‚
        - æ–‡æœ¬ç‰‡æ®µ: ç›´æ¥æ·»åŠ å…¶å†…å®¹
        - å›¾ç‰‡ç‰‡æ®µ(type==1): æ·»åŠ "[å›¾ç‰‡å†…å®¹] æè¿° [å›¾ç‰‡åœ°å€: è·¯å¾„]" æˆ–æ— è·¯å¾„æ—¶ä»…æ·»åŠ å†…å®¹
        """
        formatted = []
        if not chunks:
            return formatted
        for item in chunks:
            try:
                if isinstance(item, dict):
                    t = item.get('type', 0)
                    doc = item.get('document', '')
                    src = item.get('source', '')
                    if t == 1:
                        if src:
                            formatted.append(f"[å›¾ç‰‡å†…å®¹] {doc} [å›¾ç‰‡åœ°å€: {src}]")
                        else:
                            formatted.append(f"[å›¾ç‰‡å†…å®¹] {doc}")
                    else:
                        formatted.append(str(doc))
                else:
                    formatted.append(str(item))
            except Exception:
                # å…œåº•ï¼šæ— æ³•è§£æçš„é¡¹ç›´æ¥è½¬å­—ç¬¦ä¸²
                formatted.append(str(item))
        return formatted

#====================å­ç±»åŠ©æ‰‹====================
#å¿ƒç†åŠ©æ‰‹
class RAG_psychology(RAG):
    def __init__(self):
        psychology_id= os.getenv("APP_ID_PSYCHOLOGY")
        self.index_path =str(PSYCHOLOGY_INDEX_DIR)  # âœ… æ­£ç¡®è·¯å¾„
        self.collection = "psychology_docs"           # âœ… æ­£ç¡®é›†åˆå
        self.llm = LLM_psychology(app_id=psychology_id)
        super().__init__()

#å¥èº«é¥®é£ŸåŠ©æ‰‹
class RAG_fitness(RAG):
    def __init__(self):
        fitness_id= os.getenv("APP_ID_FITNESS")
        self.index_path = str(FITNESS_INDEX_DIR)    # âœ… æ­£ç¡®è·¯å¾„
        self.collection = "fitness_docs"              # âœ… æ­£ç¡®é›†åˆå
        self.llm = LLM_fitness(app_id=fitness_id)
        super().__init__()

#æ ¡å›­çŸ¥è¯†é—®ç­”
class RAG_compus(RAG):
    def __init__(self):
        compus_id= os.getenv("APP_ID_CAMPUS") 
        self.index_path = str(CAMPUS_INDEX_DIR)      # âœ… æ­£ç¡®è·¯å¾„
        self.collection = "campus_docs"               # âœ… æ­£ç¡®é›†åˆå
        self.llm = LLM_compus(app_id=compus_id)
        super().__init__()

#è®ºæ–‡åŠ©æ‰‹
class RAG_paper(RAG):
    def __init__(self):
        paper_id= os.getenv("APP_ID_PAPER")
        self.index_path = str(PAPER_INDEX_DIR)    # âœ… æ­£ç¡®è·¯å¾„
        self.collection = "paper_docs"                # âœ… æ­£ç¡®é›†åˆå
        self.llm = LLM_paper(app_id=paper_id)
        super().__init__()