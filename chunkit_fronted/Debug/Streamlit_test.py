import streamlit as st
import sys
import time
import re
import os
from typing import List, Dict, Any
from pathlib import Path
from Agent_test import InteractiveAgent

# é¡¹ç›®å†…æ¨¡å—å¯¼å…¥
from Utils.Path import (
    PAPER_DOCS_DIR, CAMPUS_DOCS_DIR, FITNESS_DOCS_DIR, PSYCHOLOGY_DOCS_DIR,
    PAPER_INDEX_DIR, CAMPUS_INDEX_DIR, FITNESS_INDEX_DIR, PSYCHOLOGY_INDEX_DIR,
    CAMPUS_IMAGES_PATH, CAMPUS_IMAGES_MAPPING_PATH,
)

from multiRAG import MultiRAG
from callback import LLM_model as CampusLLM  # æ ¡å›­åŸŸï¼šä½¿ç”¨MultiRAG + LLMæµå¼å›ç­”ï¼ˆå«å›¾ç‰‡ä¿¡æ¯ï¼‰

from RAGlibrary import (
    RAG_psychology,
    RAG_fitness,
    RAG_compus,
    RAG_paper,
)
from retrieve_model import retrieve_relevant_chunks

#è¿è¡Œæ–¹æ³•;
#cd demo\back-end-python\chunkit_frontedåˆ°è¿™ä¸ªç›®å½•
#ç„¶åStreamlit run Debug\Streamlit_test.pyå¯ä»¥è¿è¡Œæ­¤åŠŸèƒ½

# ----------------------------
# å·¥å…·å‡½æ•°
# ----------------------------

def parse_image_paths_from_text(text: str) -> List[str]:
    """ä»æµå¼æ®µè½æ–‡æœ¬ä¸­è§£æå‡ºå›¾ç‰‡è·¯å¾„ï¼ˆå…¼å®¹ä¸¤ç§æç¤ºæ ¼å¼ï¼‰ã€‚
    å…¼å®¹ï¼š[å›¾ç‰‡åœ°å€: D:\...] æˆ– [åœ°å€: D:\...]
    """
    paths = []
    patterns = [r"\[å›¾ç‰‡åœ°å€:\s*([^\]]+)\]", r"\[åœ°å€:\s*([^\]]+)\]"]
    for pat in patterns:
        for m in re.finditer(pat, text):
            path = m.group(1).strip()
            if path:
                paths.append(path)
    return paths


def format_matches_for_display(results: List[Dict[str, Any]]) -> str:
    """æ ¼å¼åŒ– MultiRAG.retrieve çš„åŒ¹é…ç»“æœï¼ˆå«æ–‡æœ¬ä¸å›¾ç‰‡ï¼‰ä¸ºæ˜¾ç¤ºæ–‡æœ¬ã€‚"""
    if not results:
        return "æœªæ£€ç´¢åˆ°ç›¸å…³å†…å®¹ã€‚"
    
    output = f"æ£€ç´¢åˆ° {len(results)} ä¸ªç›¸å…³ç»“æœï¼š\n\n"
    for i, r in enumerate(results, 1):
        rtype = r.get('type', 0)
        content = r.get('document', '')
        source = r.get('source', '')
        label = 'å›¾ç‰‡' if rtype == 1 else 'æ–‡å­—'
        output += f"â€”â€” ç»“æœ {i}ï¼ˆ{label}ï¼‰â€”â€”\n"
        output += content[:300] + "\n"
        if rtype == 1 and source:
            output += f"å›¾ç‰‡è·¯å¾„: {source}\n"
        output += "\n"
    
    return output


# ----------------------------
# æŸ¥è¯¢ä¸æµå¼é—®ç­”
# ----------------------------

def query_and_stream_answer(domain: str, question: str, topk: int = 5, show_sources: bool = True):
    """æŸ¥è¯¢æ£€ç´¢å¹¶æµå¼è¾“å‡ºç­”æ¡ˆã€‚æ ¹æ®é¢†åŸŸè‡ªåŠ¨é€‰æ‹©å®ç°æ–¹å¼ã€‚è¿”å›ç»“æœå’Œå›¾ç‰‡è·¯å¾„ã€‚"""
    domain = domain.lower()
    st.write(f"**é¢†åŸŸ**: {domain} | **é—®é¢˜**: {question} | **topk**: {topk}")
    
    results = []
    candidate_image_paths = []
    answer_text = ""
    
    if domain == 'campus':
        # 1) æ£€ç´¢ï¼ˆå«å›¾ç‰‡è·¯å¾„ï¼‰
        rag = MultiRAG(
            index_path=str(CAMPUS_INDEX_DIR),
            collection_name='campus_docs',
            image_output_dir=str(CAMPUS_IMAGES_PATH),
            image_mapping_file=str(CAMPUS_IMAGES_MAPPING_PATH),
        )
        results = rag.retrieve(question, topk=topk)
        
        # 2) æµå¼å›ç­”
        llm = CampusLLM()
        llm.start_LLM()
        
        # åˆ›å»ºä¸€ä¸ªç©ºçš„å ä½ç¬¦ç”¨äºæµå¼è¾“å‡º
        answer_placeholder = st.empty()
        full_text = ""
        
        try:
            for para in llm.retrieve_and_answer(question, top_k=max(5, topk)):
                full_text += para + "\n"
                answer_placeholder.markdown(full_text)
                # ä»æ®µè½ä¸­è§£æå¯èƒ½å‡ºç°çš„å›¾ç‰‡è·¯å¾„
                candidate_image_paths.extend(parse_image_paths_from_text(para))
            
            answer_text = full_text
        except Exception as e:
            st.error(f"LLM è°ƒç”¨å¤±è´¥ï¼š{e}")
            
    elif domain == 'all':
        st.subheader("æ‰¹é‡æŸ¥è¯¢å¤šä¸ªé¢†åŸŸ")
        
        # æ ¡å›­ï¼ˆå«å›¾ç‰‡ï¼‰
        st.markdown("### é¢†åŸŸ: campus")
        rag = MultiRAG(
            index_path=str(CAMPUS_INDEX_DIR),
            collection_name='campus_docs',
            image_output_dir=str(CAMPUS_IMAGES_PATH),
            image_mapping_file=str(CAMPUS_IMAGES_MAPPING_PATH),
        )
        campus_results = rag.retrieve(question, topk=topk)
        if show_sources:
            st.markdown("#### æ£€ç´¢æº:")
            st.markdown(format_matches_for_display(campus_results))
        
        st.markdown("#### å›ç­”:")
        campus_answer_placeholder = st.empty()
        campus_full_text = ""
        
        llm = CampusLLM()
        llm.start_LLM()
        try:
            for para in llm.retrieve_and_answer(question, top_k=max(5, topk)):
                campus_full_text += para + "\n"
                campus_answer_placeholder.markdown(campus_full_text)
                candidate_image_paths.extend(parse_image_paths_from_text(para))
        except Exception as e:
            st.error(f"Campus LLM è°ƒç”¨å¤±è´¥ï¼š{e}")
        
        # å…¶ä»–é¢†åŸŸï¼ˆæ–‡æœ¬ï¼‰
        rag_map = {
            'paper': RAG_paper,
            'fitness': RAG_fitness,
            'psychology': RAG_psychology,
        }
        
        for domain_name in ('paper', 'fitness', 'psychology'):
            st.markdown(f"### é¢†åŸŸ: {domain_name}")
            rag_cls = rag_map[domain_name]
            rag_agent = rag_cls()
            chunks = retrieve_relevant_chunks(
                user_query=question,
                vector_store=rag_agent.vector_store,
                embedding_model=rag_agent.model,
                cross_encoder1=rag_agent.cross_encoder,
            )
            
            if show_sources:
                st.markdown("#### æ£€ç´¢æº:")
                source_text = f"æ£€ç´¢åˆ° {len(chunks)} ä¸ªç›¸å…³æ–‡å­—ç‰‡æ®µï¼š\n\n"
                for i, c in enumerate(chunks, 1):
                    source_text += f"â€”â€” ç‰‡æ®µ {i} â€”â€”\n{c[:300]}\n\n"
                st.markdown(source_text)
            
            st.markdown("#### å›ç­”:")
            domain_answer_placeholder = st.empty()
            domain_full_text = ""
            
            try:
                for para in rag_agent.call_RAG_stream(question):
                    domain_full_text += para + "\n"
                    domain_answer_placeholder.markdown(domain_full_text)
            except Exception as e:
                st.error(f"{domain_name} LLM è°ƒç”¨å¤±è´¥ï¼š{e}")
        
        # åˆå¹¶æ‰€æœ‰ç»“æœ
        results = campus_results
        answer_text = "æŸ¥çœ‹å„é¢†åŸŸçš„è¯¦ç»†å›ç­”"
            
    elif domain in ('paper', 'fitness', 'psychology', 'compus'):
        # 1) æ£€ç´¢ï¼ˆæ–‡å­—ç‰‡æ®µï¼‰
        rag_map = {
            'paper': RAG_paper,
            'fitness': RAG_fitness,
            'psychology': RAG_psychology,
            'compus': RAG_compus,
        }
        rag_cls = rag_map[domain]
        rag_agent = rag_cls()
        chunks = retrieve_relevant_chunks(
            user_query=question,
            vector_store=rag_agent.vector_store,
            embedding_model=rag_agent.model,
            cross_encoder1=rag_agent.cross_encoder,
        )
        
        # 2) æµå¼å›ç­”
        answer_placeholder = st.empty()
        full_text = ""
        
        try:
            for para in rag_agent.call_RAG_stream(question):
                full_text += para + "\n"
                answer_placeholder.markdown(full_text)
            
            answer_text = full_text
        except Exception as e:
            st.error(f"LLM è°ƒç”¨å¤±è´¥ï¼š{e}")
    
    else:
        st.error(f"ä¸æ”¯æŒçš„é¢†åŸŸ: {domain}")
    
    # å»é‡å›¾ç‰‡è·¯å¾„
    unique_image_paths = []
    for p in candidate_image_paths:
        if p not in unique_image_paths:
            unique_image_paths.append(p)
    
    return results, answer_text, unique_image_paths


# è®¾ç½®é¡µé¢æ ‡é¢˜å’Œå›¾æ ‡
st.set_page_config(
    page_title="æ™ºèƒ½é—®ç­”ç³»ç»Ÿ",
    page_icon="ğŸ¤–",
    layout="wide",
    initial_sidebar_state="expanded",
)

# --- 1. åˆå§‹åŒ–æ™ºèƒ½ä½“ ---
# ä½¿ç”¨ st.cache_resource ç¡®ä¿æ¨¡å‹å’Œç±»åªè¢«åˆå§‹åŒ–ä¸€æ¬¡ï¼Œæé«˜åº”ç”¨æ€§èƒ½
@st.cache_resource
def load_agent():
    """
    åŠ è½½å¹¶åˆå§‹åŒ– InteractiveAgentã€‚
    æ­¤å‡½æ•°çš„ç»“æœå°†è¢«ç¼“å­˜ï¼Œé¿å…æ¯æ¬¡é¡µé¢åˆ·æ–°æ—¶éƒ½é‡æ–°åŠ è½½æ¨¡å‹ã€‚
    """
    with st.spinner("æ­£åœ¨åˆå§‹åŒ–æ™ºèƒ½ä½“ï¼Œè¯·ç¨å€™..."):
        try:
            agent = InteractiveAgent()
            return agent
        except Exception as e:
            # å¦‚æœåˆå§‹åŒ–å¤±è´¥ï¼Œæ˜¾ç¤ºé”™è¯¯å¹¶åœæ­¢åº”ç”¨
            st.error(f"æ™ºèƒ½ä½“åˆå§‹åŒ–å¤±è´¥: {e}")
            st.stop()


# --- 2. ä¾§è¾¹æ å’Œæ¨¡å¼é€‰æ‹© ---
st.sidebar.title("ğŸ› ï¸ æµ‹è¯•æ§åˆ¶å°")
st.sidebar.markdown("é€‰æ‹©ä¸€ä¸ªæ¥å£è¿›è¡Œæµ‹è¯•ï¼Œæˆ–åœ¨ä¸»çª—å£ç›´æ¥å¼€å§‹å¯¹è¯ã€‚")

test_mode = st.sidebar.radio(
    "é€‰æ‹©æµ‹è¯•æ¨¡å¼",
    ("å®Œæ•´èŠå¤© (æµå¼)", "ä»…æ„å›¾è¯†åˆ«", "RAGæ£€ç´¢é—®ç­”")
)

# --- 3. æ ¹æ®ä¸åŒæ¨¡å¼æ˜¾ç¤ºä¸åŒç•Œé¢ ---

# æ¨¡å¼ä¸€ï¼šå®Œæ•´èŠå¤©
if test_mode == "å®Œæ•´èŠå¤© (æµå¼)":
    # åŠ è½½æ™ºèƒ½ä½“å®ä¾‹
    agent = load_agent()
    
    st.title("ğŸ¤– å¤šæ™ºèƒ½ä½“èŠå¤©ç³»ç»Ÿ")
    st.caption("è¿™æ˜¯ä¸€ä¸ªç”¨äºæµ‹è¯•å¤šæ™ºèƒ½ä½“ RAG ç³»ç»Ÿçš„äº¤äº’ç•Œé¢ã€‚")

    # åˆå§‹åŒ–èŠå¤©è®°å½•
    if "messages" not in st.session_state:
        st.session_state.messages = []

    # æ˜¾ç¤ºå†å²æ¶ˆæ¯
    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])

    # æ¥æ”¶ç”¨æˆ·è¾“å…¥
    if prompt := st.chat_input("è¯·è¾“å…¥æ‚¨çš„é—®é¢˜..."):
        # å°†ç”¨æˆ·æ¶ˆæ¯æ·»åŠ åˆ°å†å²è®°å½•å¹¶æ˜¾ç¤º
        st.session_state.messages.append({"role": "user", "content": prompt})
        with st.chat_message("user"):
            st.markdown(prompt)

        # è·å–å¹¶æ˜¾ç¤ºåŠ©æ‰‹å›ç­”
        with st.chat_message("assistant"):

            full_response = ""

            try:
                # è°ƒç”¨æ ¸å¿ƒæ–¹æ³•ï¼Œè·å–æ®µè½ç”Ÿæˆå™¨
                stream_generator = agent.process_question_with_full_response(prompt, stream_mode=True)

                # éå†ç”Ÿæˆå™¨ï¼Œå¤„ç†æ¯ä¸ªè¿”å›çš„æ®µè½
                for chunk in stream_generator:
                    if chunk.get("type") == "content":
                        # ä» chunk ä¸­è·å–å¤´åƒå’Œæ®µè½å†…å®¹
                        avatar = chunk.get("avatar", "ğŸ¤–")
                        paragraph = chunk.get("delta", "")

                        if paragraph:
                            # 1. æŒ‰ç…§ä½ è¦æ±‚çš„æ ¼å¼æ„å»ºè¾“å‡ºè¡Œ
                            output_line = f"å¤´åƒ: {avatar} | å›ç­”æ®µè½: {paragraph}"

                            # 2. ä½¿ç”¨ st.markdown ç›´æ¥æ˜¾ç¤ºè¿™ä¸€è¡Œ
                            st.markdown(output_line)

                            # 3. å°†ç”Ÿæˆçš„è¡Œæ·»åŠ åˆ°å®Œæ•´å›å¤ä¸­ï¼Œç”¨äºå†å²è®°å½•
                            full_response += output_line + "\n"

                    elif chunk.get("type") == "error":
                        error_message = chunk.get("message", "æœªçŸ¥é”™è¯¯")
                        st.error(f"å¤„ç†æ—¶å‘ç”Ÿé”™è¯¯: {error_message}")
                        full_response += f"\n\n**é”™è¯¯**: {error_message}"

            except Exception as e:
                st.error(f"è°ƒç”¨æ™ºèƒ½ä½“æ—¶å‘ç”Ÿä¸¥é‡é”™è¯¯: {e}")
                full_response = "æŠ±æ­‰ï¼Œå¤„ç†æ‚¨çš„è¯·æ±‚æ—¶å‘ç”Ÿäº†ä¸¥é‡é”™è¯¯ã€‚"
                st.markdown(full_response)
            # --- æ ¸å¿ƒé€»è¾‘ä¿®æ”¹ç»“æŸ ---

        # å°†åŠ©æ‰‹çš„å®Œæ•´å›ç­”æ·»åŠ åˆ°å†å²è®°å½•
        st.session_state.messages.append({"role": "assistant", "content": full_response})


# æ¨¡å¼äºŒï¼šä»…æ„å›¾è¯†åˆ«
elif test_mode == "ä»…æ„å›¾è¯†åˆ«":
    # åŠ è½½æ™ºèƒ½ä½“å®ä¾‹
    agent = load_agent()
    
    st.title("ğŸ¯ æ„å›¾è¯†åˆ«æ¥å£æµ‹è¯•")
    st.info("åœ¨è¿™é‡Œï¼Œä½ å¯ä»¥è¾“å…¥é—®é¢˜ï¼Œç³»ç»Ÿå°†åªè°ƒç”¨ `predict_intent_only` æ–¹æ³•å¹¶è¿”å›è¯†åˆ«å‡ºçš„æ„å›¾ã€‚")

    user_input = st.text_area("è¾“å…¥è¦è¯†åˆ«çš„é—®é¢˜:", height=100,
                              placeholder="ä¾‹å¦‚ï¼šæˆ‘æƒ³å’¨è¯¢å¿ƒç†æ–¹é¢çš„é—®é¢˜ï¼Œå¹¶äº†è§£ä¸€ä¸‹æ ¡å›­å›¾ä¹¦é¦†çš„å¼€æ”¾æ—¶é—´ã€‚")

    if st.button("è¯†åˆ«æ„å›¾", use_container_width=True):
        if user_input:
            with st.spinner("æ­£åœ¨è¯†åˆ«..."):
                result = agent.predict_intent_only(user_input)

                st.subheader("è¯†åˆ«ç»“æœ (åŸå§‹JSON):")
                st.json(result)

                st.subheader("æ ¼å¼åŒ–å±•ç¤º:")
                if result.get("success") and result.get("results"):
                    for intent_info in result["results"]:
                        st.success(
                            f"**æ„å›¾:** {intent_info.get('intent', 'N/A')} "
                            f"| **å¤´åƒ:** {intent_info.get('avatar', 'N/A')}"
                        )
                else:
                    st.warning(f"æœªèƒ½æˆåŠŸè¯†åˆ«æ„å›¾ã€‚æ¶ˆæ¯: {result.get('message', 'æ— ')}")
        else:
            st.warning("è¯·è¾“å…¥é—®é¢˜åå†è¿›è¡Œè¯†åˆ«ã€‚")

# æ¨¡å¼ä¸‰ï¼šRAGæ£€ç´¢é—®ç­”
elif test_mode == "RAGæ£€ç´¢é—®ç­”":
    st.title("ğŸ” RAGæ£€ç´¢é—®ç­”ç³»ç»Ÿ")
    st.markdown("åŸºäºRAGçš„å¤šé¢†åŸŸæ™ºèƒ½é—®ç­”ç³»ç»Ÿï¼Œæ”¯æŒæ–‡æœ¬å’Œå›¾ç‰‡æ£€ç´¢")
    
    # ä¾§è¾¹æ è®¾ç½®
    domain = st.sidebar.selectbox(
        "é€‰æ‹©é¢†åŸŸ",
        ["campus", "paper", "fitness", "psychology", "compus", "all"],
        index=0,
        help="é€‰æ‹©è¦æŸ¥è¯¢çš„çŸ¥è¯†é¢†åŸŸï¼Œé€‰æ‹©'all'å°†åœ¨æ‰€æœ‰é¢†åŸŸä¸­æŸ¥è¯¢"
    )
    
    topk = st.sidebar.slider(
        "æ£€ç´¢æ•°é‡ (TopK)",
        min_value=1,
        max_value=20,
        value=5,
        help="è®¾ç½®æ£€ç´¢è¿”å›çš„ç»“æœæ•°é‡"
    )
    
    show_sources = st.sidebar.checkbox(
        "æ˜¾ç¤ºæ£€ç´¢æº",
        value=True,
        help="æ˜¯å¦æ˜¾ç¤ºæ£€ç´¢åˆ°çš„åŸå§‹å†…å®¹"
    )
    
    # ä¸»ç•Œé¢
    question = st.text_input("è¯·è¾“å…¥æ‚¨çš„é—®é¢˜:", placeholder="ä¾‹å¦‚ï¼šæ ¡å›­é‚®ç®±å¦‚ä½•ä½¿ç”¨ï¼Ÿ")
    
    if st.button("æäº¤é—®é¢˜") and question:
        with st.spinner("æ­£åœ¨æ€è€ƒä¸­..."):
            if domain != "all":
                # åˆ›å»ºä¸¤åˆ—å¸ƒå±€
                col1, col2 = st.columns([3, 1])
                
                # æ‰§è¡ŒæŸ¥è¯¢
                results, answer, image_paths = query_and_stream_answer(
                    domain=domain,
                    question=question,
                    topk=topk,
                    show_sources=show_sources
                )
                
                # åœ¨å·¦ä¾§åˆ—æ˜¾ç¤ºç­”æ¡ˆ
                with col1:
                    st.subheader("å›ç­”")
                    st.markdown(answer)
                
                # åœ¨å³ä¾§åˆ—æ˜¾ç¤ºæ£€ç´¢æºå’Œå›¾ç‰‡
                with col2:
                    if show_sources and results:
                        st.subheader("æ£€ç´¢æº")
                        st.markdown(format_matches_for_display(results))
                    
                    # æ˜¾ç¤ºå›¾ç‰‡
                    if image_paths:
                        st.subheader("ç›¸å…³å›¾ç‰‡")
                        for img_path in image_paths:
                            if os.path.exists(img_path):
                                st.image(img_path, caption=os.path.basename(img_path), use_column_width=True)
                            else:
                                st.warning(f"å›¾ç‰‡ä¸å­˜åœ¨: {img_path}")
            else:
                # å…¨é€‰æ¨¡å¼ä¸‹ç›´æ¥ä½¿ç”¨å•åˆ—å¸ƒå±€
                results, answer, image_paths = query_and_stream_answer(
                    domain=domain,
                    question=question,
                    topk=topk,
                    show_sources=show_sources
                )
                
                # æ˜¾ç¤ºå›¾ç‰‡
                if image_paths:
                    st.subheader("ç›¸å…³å›¾ç‰‡")
                    image_cols = st.columns(min(3, len(image_paths)))
                    for i, img_path in enumerate(image_paths):
                        if os.path.exists(img_path):
                            with image_cols[i % 3]:
                                st.image(img_path, caption=os.path.basename(img_path), use_column_width=True)
                        else:
                            st.warning(f"å›¾ç‰‡ä¸å­˜åœ¨: {img_path}")